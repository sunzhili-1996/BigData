# 大数据数仓项目第06天

**课程目标**

* 能够使用JDBC查询Druid中的数据
* 使用Druid进行OLAP分析
* 搭建实时数仓数据可视化项目
* 理解Druid架构原理
* 掌握使用 Superset 进行BI分析



## 使用JDBC查询Druid中的数据

Druid提供了JDBC接口，JavaWeb项目可以直接使用 JDBC 连接Druid进行实时数据分析。

![1569381271552](assets/1569381271552.png)



需求：

- 获取 metrics-kakka 数据源中，不同用户的访问次数



实现步骤：

1、创建 druid_jdbc Maven模块

2、导入依赖

3、编写JDBC代码连接Druid获取数据

- 加载Druid JDBC驱动
- 获取Druid JDBC连接
- 构建SQL语句
- 构建Statement，执行SQL获取结果集
- 关闭Druid连接



具体实现：

1、导入依赖

```xml
<dependency>
    <groupId>org.apache.calcite.avatica</groupId>
    <artifactId>avatica</artifactId>
    <version>1.13.0</version>
</dependency>
<dependency>
    <groupId>org.apache.calcite.avatica</groupId>
    <artifactId>avatica-core</artifactId>
</dependency>
```

2、获取数据

```java
/**
 * 使用JDBC操作Druid，获取实时分析结果
 */
public class Main {
    public static void main(String[] args) throws Exception {
        // 1. 加载Druid JDBC驱动
        Class.forName("org.apache.calcite.avatica.remote.Driver");
        // 2. 获取Druid JDBC连接
        Connection connection = DriverManager.getConnection("jdbc:avatica:remote:url=http://node3:8888/druid/v2/sql/avatica/", new Properties());

        // 3. 构建SQL语句
        String sql = "SELECT user, sum(views) as view_count FROM \"metrics-kafka\" GROUP BY 1 ORDER BY 1";

        // 4. 构建Statement，执行SQL获取结果集
        Statement statement = connection.createStatement();
        ResultSet resultSet = statement.executeQuery(sql);

        // 5. 迭代ResultSet
        while(resultSet.next()) {
            String user = resultSet.getString("user");
            long view_count = resultSet.getLong("view_count");
            System.out.println(user + " -> " + view_count);
        }

        // 6. 关闭Druid连接
        resultSet.close();
        statement.close();
        connection.close();
    }
}
```



## Druid实时OLAP分析

### 开发环境准备

#### **启动Druid**

1、node1节点（使用外部zk而不使用imply自带zk启动overlord和coordinator）

```shell
# 使用外部zk而不使用imply自带zk启动overlord和coordinator
/export/servers/imply-3.0.4/bin/supervise -c /export/servers/imply-3.0.4/conf/supervise/master-no-zk.conf
```

2、node2节点（启动historical和middlemanager）

```shell
/export/servers/imply-3.0.4/bin/supervise -c /export/servers/imply-3.0.4/conf/supervise/data.conf
```

3、node3节点（启动broker和router）

```shell
/export/servers/imply-3.0.4/bin/supervise -c /export/servers/imply-3.0.4/conf/supervise/query.conf
```

#### 访问WebUI

| 组件名                    | URL                            |
| ------------------------- | ------------------------------ |
| broker                    | http://node3:8888              |
| coordinator、overlord     | http://node1:8081/index.html   |
| middleManager、historical | http://node1:8090/console.html |



### 点击流日志指标分析

#### **操作步骤：**

1、打开 postman

2、修改摄取Kafka实时数据 配置文件

- 打开 `Druid实时数据分析项目_配置文件\index_kafka_dws_click_log.json`数据文件
- 修改 Kafka 集群地址
- 修改 topic 地址

3、复制JSON配置文件到 postman

4、发送请求到 http://node1:8090/druid/indexer/v1/supervisor

#### 每日PV分析

```sql
SELECT 
		  SUM("count") as totalPV
		from
		  "dws_click_log"
		where TIME_FORMAT("__time", 'yyyy-MM-dd') = '2010-09-05'
```

#### 每日UV分析

```sql
SELECT 
		  COUNT(DISTINCT "uid") as totalPV
		from
		  "dws_click_log"
		where TIME_FORMAT("__time", 'yyyy-MM-dd') = '2010-09-05'
```

#### 每日IP分析

```sql
SELECT 
		  COUNT(DISTINCT "ip") as totalIP
		from
		  "dws_click_log"
		where TIME_FORMAT("__time", 'yyyy-MM-dd') = '2010-09-05'
```

#### 每日用户访问来源流量占比（百度、知乎、新浪、首页...）

```sql
SELECT
		  referDomain,	
		  SUM("count") as total_count
		FROM
		  "dws_click_log"
		WHERE
		  TIME_FORMAT("__time", 'yyyy-MM-dd') ='2010-09-05'
		GROUP BY 1
```

#### 每日不同城市访问来源流量占比

```sql
SELECT
		  province,	
		  city,
		  SUM("count") as total_count
		FROM
		  "dws_click_log"
		WHERE
		  TIME_FORMAT("__time", 'yyyy-MM-dd') ='2010-09-05'
		GROUP BY province,city
```



### 订单数指标分析

#### **操作步骤：**

1、打开 postman

2、修改摄取Kafka实时数据 配置文件

- 打开 `Druid实时数据分析项目_配置文件\index_kafka_dws_order.json`数据文件
- 修改 Kafka 集群地址
- 修改 topic 地址

3、复制JSON配置文件到 postman

4、发送请求到 http://node1:8090/druid/indexer/v1/supervisor

#### 日订单数分析

```sql
SELECT
	  SUM("count") as total_count
	FROM
	  "dws_order"
	WHERE
	  TIME_FORMAT("__time", 'yyyy-MM-dd') = '2019-01-06' 
```



#### 周订单数分析

```sql
SELECT
	  SUM("count") as total_count
	FROM
	  "dws_order"
	WHERE
	  "__time" >= CURRENT_TIMESTAMP - INTERVAL '7' DAY
```



#### 月订单数分析

```sql
SELECT
	  SUM("count") as total_count
	FROM
	  "dws_order"
	WHERE
	"__time" >= CURRENT_TIMESTAMP - INTERVAL '1' MONTH
```



#### 今日各区域订单数（地图）

```sql
SELECT
	  areaId,
	  sum("count") as total_count
	FROM
	  "dws_order"
	WHERE
	  TIME_FORMAT("__time", 'yyyy-MM-dd') = '2019-01-06' 
	GROUP BY 1
	ORDER BY 2 DESC
```



#### 周订单数趋势分析

分析一周内每日订单数

```sql
SELECT
	  TIME_FORMAT("__time", 'yyyy-MM-dd') as "date",
	  sum("count") as total_count
	FROM  
	  "dws_order"
	WHERE
	  "__time" >= CURRENT_TIMESTAMP - INTERVAL '7' DAY
	GROUP BY 1
```



#### 今日区域订单的订单数Top8

* 按照区域分组
* 按照订单数降序排列
* 取前8条

```sql
SELECT
	  areaId,
	  SUM("count") total_count
	FROM
	  "dws_order"
	WHERE
	  TIME_FORMAT("__time", 'yyyy-MM-dd') = '2019-01-06' 
	GROUP BY 1
	ORDER BY 2 DESC
	LIMIT 8
```

#### 周销售环比分析

- 获取上周每天总销售额
- 获取本周每天中销售额

```sql
-- 上周
	SELECT
	  '上周' as "week",
	  TIME_FORMAT("__time", 'yyyy-MM-dd') as "date1",
	  SUM("totalMoney") as total_money
	FROM
	  "dws_order"
	WHERE
	  "__time" BETWEEN (CURRENT_TIMESTAMP - INTERVAL '14' DAY) AND (CURRENT_TIMESTAMP - INTERVAL '7' DAY)
	GROUP BY 1,2
	UNION ALL
	SELECT
	  '本周' as "week",
	  TIME_FORMAT("__time", 'yyyy-MM-dd') as "date1",
	  SUM("totalMoney") as total_money
	FROM
	  "dws_order"
	WHERE
	  "__time" >= CURRENT_TIMESTAMP - INTERVAL '7' DAY
	GROUP BY 1,2;
```



#### 24小时销售额分析

```sql
SELECT
	  TIME_FORMAT("__time", 'HH') as "hour",
	  SUM("totalMoney") as "totalMoney"
	FROM
	  "dws_order"
	WHERE
	  "__time" >= CURRENT_TIMESTAMP - INTERVAL '1' DAY
	GROUP BY 1
	ORDER BY 2 DESC
```



#### 今日top4地区销售排行

```sql
SELECT
	  areaId,
	  SUM("totalMoney") as "totalMoney"
	FROM
	  "dws_order"
	WHERE
	  "__time" >= CURRENT_TIMESTAMP - INTERVAL '1' DAY
	GROUP BY 1
	ORDER BY 2 DESC
	LIMIT 4
```

#### 每日实际支付买家数

```sql
SELECT 
	    COUNT(DISTINCT "userId") as "totalCount"
		FROM 
			"dws_order" 
		WHERE TIME_FORMAT("__time", 'yyyy-MM-dd') = '2019-01-06'  and isPay=1
```

#### 每日购物车支付转换率

```sql
SELECT 
		    SUM("count") as "totalCount",		--找到总的已支付的订单
		    SUM(case when isFromCart=0 then 1 else 0 end) as "cartTotalCount"	--直接下单的订单数量
			FROM 
				"dws_order" 
			WHERE TIME_FORMAT("__time", 'yyyy-MM-dd') = '2019-01-06'  and isPay=1
```



### 商品消息数指标分析

#### **操作步骤：**

1、打开 postman

2、修改摄取Kafka实时数据 配置文件

- 打开 `Druid实时数据分析项目_配置文件\index_kafka_dws_goods.json`数据文件
- 修改 Kafka 集群地址
- 修改 topic 地址

3、复制JSON配置文件到 postman

4、发送请求到 http://node1:8090/druid/indexer/v1/supervisor

#### 每日商家商品数量

```sql
SELECT
		    shopId,
				COUNT(DISTINCT "goodsId") as total_count
		FROM 
			"dws_goods"
		WHERE
		  TIME_FORMAT("__time", 'yyyy-MM-dd') ='2019-02-23'
		GROUP BY shopId
```



#### 每日商家商品品牌数量

```sql
SELECT
		    shopId,
				COUNT(DISTINCT "brandId") as total_count
		FROM 
			"dws_goods"
		WHERE
		  TIME_FORMAT("__time", 'yyyy-MM-dd') ='2019-02-23'
		GROUP BY shopId
```

#### 每日首发上架商品数

```sql
SELECT
		    shopId,
				COUNT(DISTINCT "goodsId") as total_count
		FROM 
			"dws_goods"
		WHERE
		  TIME_FORMAT("__time", 'yyyy-MM-dd') ='2019-02-23' and isSale=1
		GROUP BY shopId
```



### 购物车消息数指标分析

#### **操作步骤：**

1、打开 postman

2、修改摄取Kafka实时数据 配置文件

- 打开 `Druid实时数据分析项目_配置文件\index_kafka_dws_cart.json`数据文件
- 修改 Kafka 集群地址
- 修改 topic 地址

3、复制JSON配置文件到 postman

4、发送请求到 http://node1:8090/druid/indexer/v1/supervisor



#### 每日加入购物车次数 

```sql
SELECT
			SUM("count") as total_count
		FROM 
			"dws_cart"
		WHERE
		  TIME_FORMAT("__time", 'yyyy-MM-dd') ='2019-12-16'
```



#### 每日加入购物车买家数

```sql
SELECT
			COUNT(DISTINCT "userId") as total_count
		FROM 
			"dws_cart"
		WHERE
		  TIME_FORMAT("__time", 'yyyy-MM-dd') ='2019-12-16'

```

#### 每日加入购物车商品数

```sql
SELECT 
	    SUM("totalGoods") as "totalCount"
		FROM 
			"dws_cart" 
		WHERE TIME_FORMAT("__time", 'yyyy-MM-dd') = '2019-12-16' 
```



### 评论数指标分析

#### **操作步骤：**

1、打开 postman

2、修改摄取Kafka实时数据 配置文件

- 打开 `Druid实时数据分析项目_配置文件\index_kafka_dws_comments.json`数据文件
- 修改 Kafka 集群地址
- 修改 topic 地址

3、复制JSON配置文件到 postman

4、发送请求到 http://node1:8090/druid/indexer/v1/supervisor

#### 每日买家评价数

```sql
select 
		userId,
		SUM("count") as totalCount
		from dws_comments
		WHERE
			  TIME_FORMAT("__time", 'yyyy-MM-dd') = '2019-12-06' 
		GROUP BY userId
```



#### 每日买家评价卖家数

```sql
select 
		userId,
		shopId,
		SUM("count") as totalCount
		from dws_comments
		WHERE
			  TIME_FORMAT("__time", 'yyyy-MM-dd') = '2019-12-06' 
		GROUP BY 1,2 
```



#### 每日买家好评率

```sql
select n
			userId,
		  SUM("count") as totalCount,
		  SUM(case when starScore>'3' then "count" else 0 end) as goodCount 
		from dws_comments
		WHERE
		  TIME_FORMAT("__time", 'yyyy-MM-dd') = '2019-12-06' 
		GROUP BY userId 
```



## 数据可视化项目



操作步骤：

1、导入 itcast_dw_web 项目

2、修改 DashboardServiceImpl.java 中 Redis 服务器地址

3、修改 utils.DruidHelper 中Druid的 url 地址

4、修改druid连接字符串的表名：dws_od改成dws_order

5、启动 Jetty 服务器

6、打开浏览器访问 http://localhost:8080/itcast_dw_web



## Druid架构与原理

### Druid系统架构详解

Druid有5种节点：

- Overlord
- MiddleManager
- Coordinator
- Historical
- Broker



以下是这几个节点的主要功能：

- Overlord、MiddleManager
  - 负责处理索引任务
  - Overlord是MiddleManager的master节点
- Coordinator、Historical
  - 负责管理分发Segment
  - Coordinator是Historical的master节点
- Broker
  1. 负责接收Client查询请求
  2. 拆分子查询给MiddleManager和Historical节点
  3. 合并查询结果返回给Client



<img src="assets/druid-architecture.png" align="left" style="border:1px solid #999">



#### 索引服务

- 索引服务是数据摄入创建和销毁Segment的重要方式
- Druid提供一组支持索引服务(Indexing Service)的组件，即Overlord和MiddleManager节点
- 索引服务采用的是主从架构，Overlord为主节点，MiddleManager是从节点

索引服务架构图如下图所示：

<img src="assets/1569232759453.png" align="left">

索引服务由三部分组件组成：

- Overlord组件
  - 分配任务给MiddleManager
- MiddleManager组件
  - 用于管理Peon的
- Peon(劳工)组件
  - 用于执行任务



部署：

- MiddleManager和Overlord组件可以部署在相同节点也可以跨节点部署
- Peon和MiddleManager是部署在同一个节点上的



索引服务架构和Yarn的架构很像：

- Overlaod => ResourceManager，负责集群资源管理和任务分配
- MiddleManager => NodeManager，负责接受任务和管理本节点的资源
- Peon => Container，执行节点上具体的任务



#### Overlord节点

- Overlord是索引服务的主节点，对外负责接受索引任务，对内负责将任务分解并下发给MiddleManager
- Overlord有两种运行模式：
  - 本地模式(Local Mode)：默认模式。本地模式下的Overlord不仅负责任务协调工作，还会负责启动一些peon来完成具体的任务。
  - 远程模式(Remote Mode)：该模式下，Overlord和MiddleManager运行在不同的节点上，它仅负责任务的协调工作，不负责完成具体的任务。
- Overlord提供了一个UI客户端，可以用于查看任务、运行任务和终止任务等
  - http://node1:8090/console.html
- Overlord提供了RESETful的访问形式，所以客户端可以通过HTTP POST形式向请求节点提交任务
  - 提交任务：http://node1:8090/druid/indexer/v1/task
  - 杀死任务：http://node1:8090/druid/indexer/v1/task/{task_id}/shutdown



#### MiddleManager节点

- MiddleManager是执行任务的工作节点
- MiddleManager会将任务单独发给每个单独JVM运行的Peon
- 每个Peon一次只能运行一个任务



#### Coordinator节点

- Coordinator是Historical的mater节点，主要负责管理和分发Segment
- 具体工作就是
  - 告知Historical加载或删除Segment
  - 管理Segment副本以及负载Segment在Historical上的均衡
- Coordinator是定期运行的，通过Zookeeper获取当前集群状态，通过评估集群状态来进行均衡负载Segment
- Coordinator连接数据库(MetaStore)，获取Segment信息和规则(Rule)，Coordinator根据数据库中表的数据来进行集群 segment 管理
- Coordinator提供了一UI界面，用于显示集群信息和规则配置
  - http://node1:8081/index.html#/



#### Historical节点

- Historical节点负责管理历史Segment
- Historical节点通过Zookeeper监听指定的路径来发现是否有新的Segment需要加载
- Historical节点收到有新的Segment时候，就会检测本地cache和磁盘，查看是否有该Segment信息。如果没有Historical节点会从Zookeeper中拉取该Segment相关的信息，然后进行下载

<img src="assets/1569233208640.png" align="left" />



#### Broker节点

- Broker节点负责转发Client查询请求的
- Broker通过zookeeper能够知道哪个Segment在哪些节点上，将查询转发给相应节点
- 所有节点返回数据后，Broker会将所有节点的数据进行合并，然后返回给Client



### Druid数据存储

Druid提供对大数据集的实时摄入和高效复杂查询的性能，主要原因：**基于Datasource与Segment的数据存储结构**



#### 数据存储

- Druid中的数据存储在被称为DataSource中，DataSource类似RDMS中的table
- 每个DataSource按照时间划分，每个时间范围称为一个chunk（(比如按天分区，则一个chunk为一天)）
- 在chunk中数据由被分为一个或多个segment
  - segment是数据实际存储结构，Datasource、Chunk只是一个逻辑概念
- 每个segment都是一个单独的文件，通常包含几百万行数据
- segment是按照时间组织成的chunk，所以在按照时间查询数据时，效率非常高



![1569231660209](assets/1569231660209.png)



#### 数据分区

- Druid处理的是事件数据，每条数据都会带有一个时间戳，可以使用时间进行分区
- 上图指定了分区粒度为为天，那么每天的数据都会被单独存储和查询



#### Segment

- Segment是数据存储、复制、均衡和计算的基本单元
- Segment具备不可变性，一个Segment一旦创建完成后(MiddleManager节点发布后)就无法被修改
- 只能通过生成一个新的Segment来代替旧版本的Segment



#### Segment内部存储结构

- Druid采用列式存储，每列数据都是在独立的结构中存储
- Segment中的数据类型主要分为三种
  - 时间戳
  - 维度列
  - 指标列

![1569232209361](assets/1569232209361.png)



- 时间戳列和指标列
  - Druid采用LZ4压缩每列的整数或浮点数
  - 收到查询请求后，会拉出所需的行数据(对于不需要的列不会拉出来)，并且对其进行解压缩
- 维度列
  - 维度列需要支持filter和group by
  - Druid使用了字典编码(Dictionary Encoding)和位图索引(Bitmap Index)来存储每个维度列
  - 每个维度列需要三个数据结构
    - 需要一个字典数据结构，将维度值映射成一个整数ID
    - 使用上面的字典编码，将该列所有维度值放在一个列表中
    - 对于列中不同的值，使用bitmap数据结构标识哪些行包含这些值。



Druid针对维度列之所以使用这三个数据结构，是因为：

- 使用字典将字符串映射成整数ID，可以紧凑的表示维度数据
- 使用Bitmap位图索引可以执行快速过滤操作
  - 找到符合条件的行号，以减少读取的数据量
  - Bitmap可以快速执行AND和OR操作



#### roll-up聚合

- Druid通过一个roll-up的处理，将原始数据在注入的时候就进行汇总处理
- roll-up可以压缩我们需要保存的数据量
- Druid会把选定的相同维度的数据进行聚合操作，可减少存储的大小
- Druid可以通过 queryGranularity 来控制注入数据的粒度。 最小的queryGranularity 是 millisecond(毫秒级)



Roll-up聚合前：

| time                | app_key   | area     | value |
| ------------------- | --------- | -------- | ----- |
| 2019-10-05 10:00:00 | area_key1 | Beijing  | 1     |
| 2019-10-05 10:30:00 | area_key1 | Beijing  | 1     |
| 2019-10-05 11:00:00 | area_key1 | Beijing  | 1     |
| 2019-10-05 11:00:00 | area_key2 | Shanghai | 2     |

Roll-up聚合后：

| time       | app_key   | area     | value |
| ---------- | --------- | -------- | ----- |
| 2019-10-05 | area_key1 | Beijing  | 3     |
| 2019-10-05 | area_key2 | Shanghai | 2     |



#### 位图索引

以下为一个DataSource（表）中存储的数据。

![1569233962963](assets/1569233962963.png)

- 第一列为时间，Appkey和area都是维度列，value为metric列
- Druid会在导入阶段自动对数据进行Rollup，将维度相同组合的数据进行聚合处理



按天聚合后的数据如下

![1569234047981](assets/1569234047981.png)



Druid通过建立位图索引，来实现快速进行数据查找。

索引如下所示：

![1569234087084](assets/1569234087084.png)

- 索引位图可以看作是HashMap<String, Bitmap>
  - key就是维度的取值
  - value就是该表中对应的行是否有该维度的值

![1569244140364](assets/1569244140364.png)



以SQL查询为例：
1）boolean条件查询

```SQL
select 
	sum(value) 
from AD_areauser 
where 
	time=’2017-10-11’ and 
	Appkey in (‘appkey1’,’appkey2’) and 
	area=’北京’
```

执行过程分析：

1. 根据时间段定位到segment
2. Appkey in ('appkey1', 'appkey2') and area=’北京’查到各自的bitmap
   - (appkey1(1000) or appkey2(0110)) and (北京(1100) ) = 1000 or 0110 = 1110
   - (1000 or 0110) and 1100 = 1110 and 1100 = 1100
   - 符合条件的列为第一行和第二行，这两行的 sum(value) 的和为26.



2）group by 查询

```sql
select 
	area, 
	sum(value) 
from AD_areauser 
where 
	time=’2017-10-11’and 
	Appkey in (‘appkey1’,’appkey2’) 
group by area
```

该查询与上面的查询不同之处在于将符合条件的列

- appkey1(1000) or appkey2(0110) = (1110)
- 将第一行、第二行、第三行取出来
- 在内存中做分组聚合。结果为：北京：26， 上海：13.

本次项目使用Druid来进行实时OLAP分析，通过Flink预处理Kafka的数据，再将预处理后的数据下沉到Kafka中。再基于Druid进行数据分析。



## Superset

### BI VS 报表工具

* 报表工具是数据展示工具，而BI（商业智能）是数据分析工具。报表工具可以制作各类数据报表、图形报表的工具，甚至还可以制作电子发票联、流程单、收据等。

* BI可以将数据进行模型构建，制作成Dashboard，相比于报表，侧重点在于分析，操作简单、数据处理量大。常常基于企业搭建的数据平台，连接数据仓库进行分析。



### 简介

Superset是一款开源的现代化企业级BI。它是目前开源的数据分析和可视化工具中比较好用的，功能简单但可以满足我们对数据的基本需求，支持多种数据源，图表类型多，易维护，易进行二次开发。 

#### 功能

- 丰富的数据可视化集
- 易于使用的界面，用于浏览和可视化数据
- 创建和共享仪表板
- 与主要身份验证提供程序（数据库，OpenID，LDAP，OAuth和REMOTE_USER通过Flask AppBuilder集成）集成的企业就绪身份验证
- 可扩展的高粒度安全性/权限模型，允许有关谁可以访问单个要素和数据集的复杂规则
- 一个简单的语义层，允许用户通过定义哪些字段应显示在哪些下拉列表中以及哪些聚合和功能度量可供用户使用来控制如何在UI中显示数据源
- 通过SQLAlchemy与大多数说SQL的RDBMS集成
- 与Druid.io的深度集成

#### 支持的数据库

superset现在支持的所有数据库或分析引擎：

![1571136008014](assets/1571136008014-1571491503570.png)

- [Amazon Athena](https://aws.amazon.com/athena/)
- [Amazon Redshift](https://aws.amazon.com/redshift/)
- [Apache Drill](https://drill.apache.org/)
- [Apache Druid](http://druid.io/)
- [Apache Hive](https://hive.apache.org/)
- [Apache Impala](https://impala.apache.org/)
- [Apache Kylin](http://kylin.apache.org/)
- [Apache Pinot](https://pinot.incubator.apache.org/)
- [Apache Spark SQL](https://spark.apache.org/sql/)
- [BigQuery](https://cloud.google.com/bigquery/)
- [ClickHouse](https://clickhouse.yandex/)
- [Google Sheets](https://www.google.com/sheets/about/)
- [Greenplum](https://greenplum.org/)
- [IBM Db2](https://www.ibm.com/analytics/db2/)
- [MySQL](https://www.mysql.com/)
- [Oracle](https://www.oracle.com/database/)
- [PostgreSQL](https://www.postgresql.org/)
- [Presto](http://prestodb.github.io/)
- [Snowflake](https://www.snowflake.com/)
- [SQLite](https://www.sqlite.org/)
- [SQL Server](https://www.microsoft.com/en-us/sql-server/)
- [Teradata](https://www.teradata.com/)
- [Vertica](https://www.vertica.com/)

#### 界面

![1571037718862](assets/1571037718862-1571491503568.png)

### 安装

#### 安装python3

首先升级python版本，我们使用Anaconda来安装Python3版本的python。



1、首先去Anaconda官网下载安装脚本

`资料\superset\Anaconda3-2019.07-Linux-x86_64.sh`



2、上传Anaconda3-2019.07-Linux-x86_64.sh

使用 FileZilla 上传到node3 /export/softwares



3、运行Anaconda3-2019.07-Linux-x86_64.sh脚本

```shell
sh Anaconda3-2019.07-Linux-x86_64.sh
```



安装过程输入：回车、yes、

Anaconda安装目录设置为：/export/servers/anaconda

 

4、配置环境变量

```shell
vim /etc/profile
#Anaconda 
export PATH=$PATH:/root/anaconda3/bin
source /etc/profile
```



5、验证是否安装python3成功

```sql
python3
```



提示出现python3.x版本即安装成功！！

退出使用quit();

注意：对于重新打开的终端连接会出现base字样，消除方法：

```sql
若在终端中输入conda deactivate，也可消除base字样，但是一次性的，再次打开终端依然存在base字样。在.bashrc文件（home目录下）添加命令：conda deactivate可以永久消除base字样。
```

至此python3已经安装成功。



#### 安装superset



1、安装依赖

```shell
yum upgrade python-setuptools
yum install gcc gcc-c++ libffi-devel python-devel python-pip python-wheel openssl-devel libsasl2-devel openldap-devel
```



1、pip安装superset

```sql
cd /export/servers/anaconda3/
pip install superset
```

需要联网下载文件等待一段时间

![1571493314416](assets/1571493314416.png)



2、创建管理员用户名和密码

```sql
fabmanager create-admin --app superset
```

![1571493718318](assets/1571493718318.png) 

记住以下信息，登录使用：

```sql
Username [admin]: admin
User first name [admin]: admin
User last name [user]: admin
Email [admin@fab.org]: 
Password: 123456
Repeat for confirmation: 123456
Recognized Database Authentications.
Admin User admin created.
```

3、初始化superset

```sql
superset db upgrade
```



4、装载初始化数据

```sql
superset load_examples
```



5、创建默认角色和权限

```sql
superset init
```



6、启动superset

```sql
superset run -h node3 -p 8080 --with-threads --reload --debugger
```

![1571529541183](assets/1571529541183.png)



7、登录superset

[http://node3:8080/superset/welcome](http://node3:8080/)

用户名： admin

密码：123456



切换到中文

 ![1571529492624](assets/1571529492624.png)



8、Superset 初体验

![1571530919443](assets/1571530919443.png)



### superset入门案例

需求：

* 使用Superset展示不同性别的用户人数

* 效果图

![1571543086714](assets/1571543086714.png)



准备环境

```shell
yum install python-devel -y
yum install mysql-devel -y
yum install gcc -y
pip install mysqlclient
```



实现步骤：

1、导入MySQL数据源

导入资料中的  `superset\数据源\superset_demo.sql`



2、添加新的数据库

mysql的url地址

```sql
mysql://root:123456@node1/superset_demo?charset=utf8
```

<img src="assets/1571543686973.png" align="left" />

![1571543732584](assets/1571543732584.png)



3、点击 SQLLab > SQL Editor编写以下SQL语句

选择 数据库

选择表，查看表的列

<img src="assets/1571571903745.png" align="left" />



参考SQL语句：

```sql
select
	case when gender = 0 then '男'
		when gender = 1 then '女'
		else '保密'
    end as gender,
	count(id) as total_cnt
from 
	t_user
group by gender
```



4、保存查询



5、点击 saved queries

![1571544326994](assets/1571544326994.png)



* 运行查询，点击 Explore 浏览数据

![1571543342386](assets/1571543342386.png)



6、配置图表类型为 Bar Chart 条形图

<img src="assets/1571543447586.png" align="left" />



7、指定统计指标 sum(total_cnt)

8、指定序列为 gender（性别）

<img src="assets/1571543490325.png" align="left" />



### Superset功能介绍

* 用户权限
* Sources
* Manage
* Charts
* Dashboards
* SQL Lab

### Superset实战 - MySQL订单分析案例

#### Superset Charts图表展示实战

1、根据日期统计，每日订单总额（趋势图）

![1571557353530](assets/1571557353530.png)



```sql
select 
	str_to_date(date1,'%Y-%m-%d') date1,
	sum(price) total_price
from
	dm_sales
group by date1;
```



2、根据日期、渠道统计订单总额（Sunburst Chart）

```sql
select
	date1,
	channelname,
	sum(price) total_price
from
	dm_sales
group by 
	date1,
	channelname
```



![1571554964846](assets/1571554964846.png)





3、根据日期、区域统计订单总额（数据透视表）

```sql
select
	str_to_date(date1,'%Y-%m-%d') date1,
	regionname,
	sum(amount) as total_amount,
	sum(price) as total_price
from
	dm_sales
group by
	date1,
	regionname
```



![1571557937832](assets/1571557937832.png)



4、根据日期、区域、渠道、产品统计订单数、订单总额（层级环图）

```sql
select
	date1,
	regionname,
	channelname,
	productname,
	sum(price) as total_price
from
	dm_sales
group by
	date1,
	regionname,
	channelname,
	productname
```



![1571556010480](assets/1571556010480.png)



#### Superset Dashboards看板展示实战

将之前设计好的图标整合到看板中



操作步骤：

1、点击 Dashboards > 添加看板

2、拖动之前开发好的 Charts 到看板中



![1571558518806](assets/1571558518806.png)



### Superset权限控制

Superset初始化权限之后，创建5个角色，分别为Admin，Alpha，Gamma，sql_lab以及Public。Admin，Alpha和Gamma角色，分配了很多的菜单/视图权限，如果手工去修改，改错的可能性很大，加之Superset并没有说明每一项权限的完整文档，所以不建议去修改这些角色的定义。灵活使用预置的角色，可以快速满足业务上安全控制需求。 

#### 角色权限介绍

* Admin：拥有所有权限

* Alpha：能访问所有数据源，增加或者更改数据源，但不能给更改其他用户权限。

* Gamma：必须结合其他能访问数据源的角色才能访问数据。这个角色所能访问的切片和看板，也是基于能访问数据源所创建的切片和看板。

* sql_lab：能访问SQL Lab菜单。

* Public：默认没有任何权限

#### 匿名访问 

所有用户都能访问某一个看板，需要进行如下设置 ：



1、更改config.py文件，设置如下部分，PUBLIC_ROLE_LIKE_GAMMA = True				

```sql
vim /export/servers/anaconda3/lib/python3.7/site-packages/superset/config.py
```



2、需要运行superset init命令，这个命令会给“Public”角色设置与“Gamma”一样的权限

```sql
superset init
```



3、将匿名用户所需要访问的数据库和数据源分配给“Public”角色。例如，基于superset_demo数据库的grade_test创建了看板，如果匿名用户需要查看这个看板，那将如下权限分配给“Public”。

* all database access on all_database_access
* all datasource access on all_datasource_access

![1571565112200](assets/1571565112200.png)



* 删除一些菜单权限：

<img src="assets/1571561021961.png" align="left" style="border:1px solid #999"/>



#### 分享页面或者嵌入html

![1571565292533](assets/1571565292533.png)



html页面：

```html
<html>
<head>
<title>dashboard</title>
</head>
<body>
    <div class="dashboard">
       <!-- <iframe src="http://node3:8080/superset/dashboard/7/"  style="height=100%; width=100%" ></iframe > -->
		
		<iframe name="myframe" src="http://node3:8080/r/10" frameborder="0" scrolling="auto" width="100%" height="100%" onload="document.all['myframe'].style.height=myframe.document.body.scrollHeight" ></iframe>
    </div>
	</body>
</html>
```



#### 角色介绍

实际业务中，不同的职能部门访问的数据不一样，例如财务部需要访问成本，应收，应付等数据，供应链需要访问库存数量，发货数据等，怎样简洁的设置，快速满足这种业务需求？

如前文所述，“Gamma”拥有大部分基础的权限，但是必须结合其他能访问数据源的角色才能访问数据。所以，可以给用户分配“Gamma”角色和针对部门分别创建的数据源角色来进行控制。

例如，针对财务用户，创建角色“Finance”，将成本，应收，应付的数据表权限赋予这个角色，财务用户就分配“Gamma”和“Finance”。

针对供应链用户，创建角色“SCM”，将库存和发货数据表权限赋予这个角色，供应链用户就配“Gamma”和“SCM”。

如果是公司的霸道总裁，需要看所有的看板，就可以给霸道总裁赋予“Gamma”和“Finance”，“SCM”角色。

![1571561162719](assets/1571561162719.png)



我们创建2个角色，分别是main角色可以查看访问main的数据，

examples角色可以查看和访问 examples 数据源。



1、创建 main 角色

* database access on [main] 拥有访问 main 数据库的权限
* datasource access on [main] 拥有访问main 数据源的权限
* can dashboard on Superset 拥有访问 main 数据源创建的 dashboard的权限



![1571565519420](assets/1571565519420.png)



2、创建examples角色

- database access on [examples] 拥有访问 examples数据库的权限
- datasource access on [examples] 拥有访问examples数据源的权限
- can dashboard on Superset 拥有访问 examples数据源创建的 dashboard的权限



![1571565640519](assets/1571565640519.png)



3、创建用户

* main_user:  关联gamma、sqllab与main角色；

![1571566545894](assets/1571566545894.png)

* examples_user: 关联gamma、sqllab与examples角色；

![1571566579297](assets/1571566579297.png)



* 用不同的用户登录查看每个用户具有的table，以及能查看到的dashboard!!





### 使用Supset进行业务开发



#### Superset对接MySQL展示离线指标数据

准备：

* 导入 `资料\superset\数据源\ads_dim_table.sql`



1、添加之前离线阶段开发好的 itcast_ads_shop 数据库数据源

* jdbc连接：mysql://root:123456@node1/itcast_ads_shop?charset=utf8



2、统计指定日期 按照大区获取订单总额

```sql
select
	t2.orgname as regionname,
	allprice
from
	ads_trade_order t1
	left join itcast_org t2
	on t1.regionid = t2.orgid
where dt = '20190905' and regionid != '9999'
```



![1571573788337](assets/1571573788337.png)



2、统计指定日期 按照大区、商品一级分类ID、订单总额

```sql
select
	t4.orgname,
	t2.catname,
	allprice
from
	ads_trade_order t1
    left join itcast_goods_cats t2 
	on t1.firstcatid  = t2.catId 
	left join itcast_goods_cats  t3
	on t1.secondcatid  = t3.catId 
	left join itcast_org t4
	on t1.regionid  = t4.orgId 
	left join itcast_org t5
	on t1.cityid  = t5.orgId 
where dt = '20190905' and regionid != '9999' and firstcatid != '9999'
```



![1571561502984](assets/1571561502984.png)



#### Superset对接Kylin展示离线指标数据

环境准备：

* 添加 kylin 支持

```shell
 pip install kylinpy
```

* 启动Kylin
	* 启动HDFS
	* 启动HBASE
	* 启动Hive metastore、hiveserver2



添加 kylin JDBC数据库

* kylin的JDBC url 为

```shell
kylin://ADMIN:KYLIN@node1:7070/itcast_shop
```



1、统计大区、店铺分类、支付方式订单总额

```sql
select 
    REGIONID ,
    SHOPID ,
    PAYTYPE ,
    SUM (GOODSPRICE ) total_money
FROM TMP_ORDER_GOODS_CAT_ORG 
group by REGIONID, SHOPID ,PAYTYPE 
```



![1571562473243](assets/1571562473243.png)



2、统计大区、一级分类、支付方式订单笔数、订单总额

```sql
select 
    REGIONID ,
    FIRSTCAT ,
    PAYTYPE ,
    count(DISTINCT ORDERID ) total_amount,
    SUM (GOODSPRICE ) total_money
FROM TMP_ORDER_GOODS_CAT_ORG 
group by REGIONID, FIRSTCAT , PAYTYPE  
```



![1571562814853](assets/1571562814853.png)



#### Superset对接Druid展示订单实时指标数据

**1、环境准备**

安装依赖

```shell
pip install pydruid
```



Druid的JBDC URL为

- druid://node3:8888/druid/v2/sql/



2、创建druid的database

![1571574940337](assets/1571574940337.png)



3、今日top4地区销售排行

![1571575356141](assets/1571575356141.png)



```sql
SELECT
areaId,
SUM("totalMoney") as totalMoney
FROM
  dws_od
WHERE
__time > CURRENT_TIMESTAMP - INTERVAL '1' DAY
GROUP BY 1
ORDER BY 2 DESC
LIMIT 4
```



4、Top8区域订单的订单数

![1571575684817](assets/1571575684817.png)



```sql
SELECT
  areaId,
  SUM("count") as totalCnt
FROM
  dws_od
GROUP BY 1
ORDER BY 2 DESC
LIMIT 8
```



#### 创建看板

![1571575861250](assets/1571575861250.png)


